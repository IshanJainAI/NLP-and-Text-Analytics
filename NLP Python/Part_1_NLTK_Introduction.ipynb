{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part 1 - NLTK Introduction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9mlGw1zBT21"
      },
      "source": [
        "**Python NLTK Natural Language Tool Kit**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrYOvHZ1umqV"
      },
      "source": [
        "1. Exploring the NLTK corpus\n",
        "2. Dictionary definitions\n",
        "3. Punctuation and stop words\n",
        "4. Stemming and lemmatization\n",
        "5. Sentence and word tokenizers\n",
        "6. Parts of speech tagging\n",
        "7. word2vec\n",
        "8. Clustering and classifying\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzEJSVCBs3WK"
      },
      "source": [
        "import nltk  \n",
        "nltk.download('book')\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('genesis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBNJPh0MwlFz"
      },
      "source": [
        "from nltk.book import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQN8PFZKycDc",
        "outputId": "5b2cc539-e4cb-42b3-cff4-625af31e6eed"
      },
      "source": [
        "texts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJZZQs2ryd1M",
        "outputId": "519096e5-b5b5-46e6-a386-2edead9e2555"
      },
      "source": [
        "sents()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sent1: Call me Ishmael .\n",
            "sent2: The family of Dashwood had long been settled in Sussex .\n",
            "sent3: In the beginning God created the heaven and the earth .\n",
            "sent4: Fellow - Citizens of the Senate and of the House of Representatives :\n",
            "sent5: I have a problem with people PMing me to lol JOIN\n",
            "sent6: SCENE 1 : [ wind ] [ clop clop clop ] KING ARTHUR : Whoa there !\n",
            "sent7: Pierre Vinken , 61 years old , will join the board as a nonexecutive director Nov. 29 .\n",
            "sent8: 25 SEXY MALE , seeks attrac older single lady , for discreet encounters .\n",
            "sent9: THE suburb of Saffron Park lay on the sunset side of London , as red and ragged as a cloud of sunset .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCBMXSL_w5kq",
        "outputId": "d748d3a2-f0a1-4189-a70e-ea8096664875"
      },
      "source": [
        "print(type(text1))\n",
        "print(len(text1))\n",
        "print(len(set(text1)))\n",
        "print(text1[:12])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'nltk.text.Text'>\n",
            "260819\n",
            "19317\n",
            "['[', 'Moby', 'Dick', 'by', 'Herman', 'Melville', '1851', ']', 'ETYMOLOGY', '.', '(', 'Supplied']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIplACads6xv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b22dfd8-1751-4cb5-b81a-7c8459d6a6e9"
      },
      "source": [
        "print(type(sent1))\n",
        "print(len(sent1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set(text1)"
      ],
      "metadata": {
        "id": "jBTXpJUyXQAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCsWqt0cs63e",
        "outputId": "9d65e174-33de-4f7a-bc64-4a79bfaa3f3b"
      },
      "source": [
        "from nltk.corpus import gutenberg\n",
        "print(gutenberg.fileids())\n",
        "\n",
        "hamlet = gutenberg.words('shakespeare-hamlet.txt')\n",
        "print(len(hamlet))\n",
        "\n",
        "hamlet_sentences = gutenberg.sents('shakespeare-hamlet.txt')\n",
        "print(len(hamlet_sentences))\n",
        "\n",
        "print(hamlet_sentences[1024])\n",
        "\n",
        "print(len(gutenberg.paras('shakespeare-hamlet.txt')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n",
            "37360\n",
            "3106\n",
            "['What', 'say', 'you', '?']\n",
            "950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiKEIguq0suD",
        "outputId": "be5ca25b-21f3-464a-8969-74f008e301ce"
      },
      "source": [
        " file1 = nltk.corpus.gutenberg.words('austen-persuasion.txt')\n",
        " print(file1[0:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[', 'Persuasion', 'by', 'Jane', 'Austen', '1818', ']', 'Chapter', '1', 'Sir']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDgWrMFr1MIC"
      },
      "source": [
        "Get the count of a word in a document, or the context of every occurence of a word in a document"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFnbN2lSs641",
        "outputId": "919ceb61-3357-4553-c407-7811c485c07e"
      },
      "source": [
        "print(text1.count('horse')) # count a specific word\n",
        "print(text1.concordance('passion')) # NLTK concordance Index keeps track of the keyword index in the passage/text and retrieve the surrounding words.\n",
        "print(text2.concordance('passion'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26\n",
            "Displaying 7 of 7 matches:\n",
            "r him ,\" said I , now flying into a passion again at this unaccountable farrago\n",
            " employed in the celebration of the Passion of our Lord ; though in the Vision \n",
            "ce all mortal interests to that one passion ; nevertheless it may have been tha\n",
            "ing with the wildness of his ruling passion , yet were by no means incapable of\n",
            "it , however promissory of life and passion in the end , it is above all things\n",
            "o ' s lordly chest . So have I seen Passion and Vanity stamping the living magn\n",
            " Guernseyman , flying into a sudden passion . \" Oh ! keep cool -- cool ? yes , \n",
            "None\n",
            "Displaying 5 of 5 matches:\n",
            "one ,\" said Elinor , \" who has your passion for dead leaves .\" \" No ; my feelin\n",
            "r daughters , without extending the passion to her ; and Elinor had the satisfa\n",
            "r , if he was to be in the greatest passion !-- and Mr . Donavan thinks just th\n",
            "edness I could have borne , but her passion -- her malice -- At all events it m\n",
            "ling a sacrifice to an irresistible passion , as once she had fondly flattered \n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cA0guUDu1-FP"
      },
      "source": [
        "FreqDist and most_common\n",
        "\n",
        "We can use FreqDist to find the number of occurrences of each word in the text.\n",
        "By getting len(vocab) we get the number of unique words in the text (including punctuation).\n",
        "\n",
        "And we can get the most common words easily too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoBxcV-R1OW1",
        "outputId": "5800d029-b357-4f04-e06e-df9320ee0ee9"
      },
      "source": [
        "vocab = nltk.FreqDist(text1)\n",
        "print(len(vocab))\n",
        "print(vocab.most_common(20))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19317\n",
            "[(',', 18713), ('the', 13721), ('.', 6862), ('of', 6536), ('and', 6024), ('a', 4569), ('to', 4542), (';', 4072), ('in', 3916), ('that', 2982), (\"'\", 2684), ('-', 2552), ('his', 2459), ('it', 2209), ('I', 2124), ('s', 1739), ('is', 1695), ('he', 1661), ('with', 1659), ('was', 1632)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "WG9_45jl3G-U",
        "outputId": "d6ada6d7-8bb4-472c-b1c7-9c4097e84ed3"
      },
      "source": [
        "w = vocab.most_common(20)\n",
        "w[0][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "','"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVcXf46m2h5U"
      },
      "source": [
        "\n",
        "Here we got the 80 most common words, filtered only the ones with at least 3 characters, then sorted them descending by number of occurences.\n",
        "\n",
        "A better way is to first remove all the stop words (see below), then get the FreqDist."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1QvIyL21Obg",
        "outputId": "96420e21-a99c-4e2a-b683-57416ffb0d0d"
      },
      "source": [
        "mc = sorted([w for w in vocab.most_common(80) if len(w[0]) > 3], key=lambda x: x[1], reverse=True)\n",
        "# The sorted() function returns a sorted list of the specified iterable object.You can specify ascending or descending order. Strings are sorted alphabetically, and numbers are sorted numerically.\n",
        "print(mc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('that', 2982), ('with', 1659), ('this', 1280), ('from', 1052), ('whale', 906), ('have', 760), ('there', 715), ('were', 680), ('which', 640), ('like', 624), ('their', 612), ('they', 586), ('some', 578), ('then', 571), ('when', 553), ('upon', 538), ('into', 520), ('ship', 507), ('more', 501), ('Ahab', 501), ('them', 471), ('what', 442), ('would', 421), ('been', 415), ('other', 412), ('over', 403)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpdLz-wl352Z"
      },
      "source": [
        "A dispersion plot shows you where in the document a word is used. You can pass in a list of words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "mi8DffQF1OeV",
        "outputId": "09e1eedb-a770-4a67-ee46-79a902ad3e33"
      },
      "source": [
        "text1.dispersion_plot(['capture', 'whale', 'life', 'death', 'kill'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAf2klEQVR4nO3de5hcVZnv8e8vBJJ5CCQgEVAgLaBcdSI0igh2iw5HOShnzoDioBLHZxBHcJg5yEHhIT2oI3iBqKiAl4nOwICIjg56FBTDRQzSgXCRuxLkohKQWxhBCO/5Y689vbvYtaqqu7qrk/59nqeeqr3X2mu9a+1d9fbetVNRRGBmZtbMjF4HYGZmU5sThZmZZTlRmJlZlhOFmZllOVGYmVmWE4WZmWU5Udg6R9J+km7vQjurJL1xHNsfLumS8cbRLd2alzH0G5J2nOx+bfI4UdiEG+8HcqOIuDIidupWe3UkLZX0J0lPpMfNkj4haW4ljnMj4oCJjKMTEzUvkvpSMliTHqsknTCGdhZJuqrb8dnEc6Iwa+6TEbEJMB94D7A38DNJG/cqIEkb9KpvYF5EzAHeAZws6U09jMUmkROF9YykGZJOkPQrSQ9L+qakzVPZlyRdVKl7mqSfqDAo6b5K2baSvi1pdWrnzLR+B0mXpXUPSTpX0rxO44yIpyLiWuCtwAsoksaov5BTXGdIelDS45JukrR7Klsq6SxJl6azk8slLajEv3Mq+4Ok2yW9rVK2NM3FDyQ9Cbxe0oGSbklt3S/puFS3cV52kbRM0qOSfinprQ3tfkHS91M710jaoc35+DnwS2D3xjJJcyV9I+2LeySdlPbzLsBZwGvSWcmj7e8B6zUnCuulY4D/BQwALwIeAb6Qyv4P8PL0Ybwf8F7giGj4zZn0F/bFwD1AH/Bi4PyyGPhEansXYFtgaKzBRsQTwKXAfjXFBwCvA14GzAXeBjxcKT8c+CiwBbASODfFv3Fq8zzghcBhwBcl7VrZ9q+BjwObAFcBXwXel852dgcuawxG0obAfwKXpHaPAc6VVL00dRjwT8BmwF2pj6yUEF8L7AZcX1Pl82n821Ps13cD74mIW4GjgJ9HxJyI6DhhW+84UVgvHQWcGBH3RcTTFB/ih0iaGRH/BbwLOB34N+CYiLivpo1XUSSCD0XEk+mv/6sAIuKuiLg0Ip6OiNWprYFxxvwAsHnN+mcoPsh3BhQRt0bEbyvl34+IK9I4T6T4y3pb4CBgVUT8S0Q8GxHXAxcBh1a2/W5E/CwinouIp1Jfu0raNCIeiYjrauLZG5gDnBoRf4qIyygS6jsqdb4TEb+IiGcpEtfCFmN/CPgD8BXghIj4SbUwJe3DgA9HxBMRsQr4DMV+tHWYE4X10gLgO+nSyKPArcBaYEuAiLgG+DXFmcE3m7SxLXBP+rAbRdKWks5Pl2cep0g4W4wz5hdTfFiOkj6Iz6Q4I3pQ0jmSNq1UubdSd01q40UUc/Dqcg7SPBwObFW3bfJXwIHAPeky1mtq4nwRcG9EPFdZd0+Kv/S7yuv/okgsOVtExGYRsUtEfK6uHNgw9dOsT1sHOVFYL90LvDki5lUesyPifgBJHwBmUfwVf3ymje0kzawp+2cggJdHxKbAOymSzphImgO8EbiyrjwiPhcRewK7UlyC+lCleNuGdjanGNe9wOUNczAnIt5fbbqhn2sj4mCKS0r/QX0SfQDYVlL1Pb4dcH97ox2ThyjOdhZU1lX79E9Vr6OcKGyybChpduUxk+LLzY+XX+xKmi/p4PT6ZcDHKD7c3wUcL6nu0sgvgN8Cp0raOLX92lS2CbAGeEzSixn9wd02SbMk7UnxofwI8C81dfaS9Or03cCTwFNA9a/5AyXtK2kjiu8qlkfEvRSXg14m6V2SNkyPvdKXv3WxbKTi32/MjYhngMcb+ildQ3GWcHxqcxB4CyPf33RdRKylSFofl7RJ2q//SHEmB/B7YJs0B7YOcaKwyfID4I+VxxDwWeB7wCWSngCWU1yGmUnx4XJaRNwQEXcCHwH+VdKsaqPpw+ktwI7Ab4D7gLen4n8C9gAeA74PfLvDmI9PcT0MfANYAewTEU/W1N0U+DJFIrknbfOpSvl5wGKKS057UiTA8gvyAyiu7T9AcTnoNIozqWbeBaxKl9OOorhUNUpE/IliXt5M8Zf+F4F3R8Rt7Qx8HI6hSJS/pvji/Tzga6nsMoq7pX4n6aEJjsO6SP6Pi8wmlqSlwH0RcVKvYzEbC59RmJlZlhOFmZll+dKTmZll+YzCzMyy6u49X6dtscUW0dfX1+swzMzWKStWrHgoIubXla13iaKvr4/h4eFeh2Fmtk6RdE+zMl96MjOzLCcKMzPLcqIwM7MsJwozM8tyojAzsywnCjMzy3KiMDOzLCcKMzPLcqIwM7MsJwozM8tyojAzsywnCjMzy3KiMDOzLCcKMzPLcqIwM7MsJwozM8tyojAzsywnCjMzy3KiMDOzLCcKMzPLcqIwM7MsJwozM8tyojAzsywnCjMzy3KiMDOzLCcKMzPLcqIwM7MsJwozM8tyojAzsywnCjMzy3KiMDOzrElJFBJ9En89GX2ZmVl3TdYZRR90nigkNuh+KO0bGupl7+uWqTJX1TgmK6a6flr13e3Yejn/zfoeGpq4uDppd6ocm93Qq7EoIlpXEu8GjgMCuBH4JnASsBHwMHB4BL+XGAJ2AHYEtgA+GcGXJZYDuwB3A18HHgH6Izg6tX8x8OkIlkmsAc4G3gh8gCLJfDD1dQ3wdxGsbRZrf39/DA8PdzgNTcdNG9NjTJ25qsYxWTHV9dOq727H1sv5b9a3VDxPRFydjHeqHJvdMJFjkbQiIvrrylqeUUjsRpEU9o/gz4G/B64C9o7glcD5wPGVTV4B7A+8BjhZ4kXACcCVESyM4IwWXW4MXJP6ehh4O/DaCBYCa4HDW8VsZmbdM7ONOvsDF0bwEEAEf5B4OXCBxNYUf+nfXan/3Qj+CPxR4qfAq4BHO4hpLXBRev0GYE/g2vTXyZ8BDzZuIOlI4EiA7bbbroOuzMyslbF+R/F54MwIXg68D5hdKWs8Mao7UXq2oe/q9k9VLi0J+Ho6E1kYwU4RDDU2FhHnRER/RPTPnz+/07GYmVlGO4niMuBQiRcASGwOzAXuT+VHNNQ/WGJ2qj8IXAs8AWxSqbMKWCgxQ2JbirOOOj8BDpF4Ydm3xII2YjYzsy5peekpgl9KfBy4XGItcD0wBFwo8QhFInlJZZMbgZ9SfJn90QgekFgNrJW4AVgKLKG4XHULcCtwXZO+b5E4CbhEYgbwDMUX3PeMYawdW7x4MnpZP0yVuarGMVkx1fXTqu9ux9bL+W/W90TG1EnbU+XY7IZejaWtu57abqy462lNBJ/uWqMd6uZdT2Zm08W47noyM7PprZ27ntpW90WzmZmt23xGYWZmWU4UZmaW5URhZmZZThRmZpblRGFmZllOFGZmluVEYWZmWU4UZmaW5URhZmZZThRmZpblRGFmZllOFGZmluVEYWZmWU4UZmaW5URhZmZZThRmZpblRGFmZllOFGZmluVEYWZmWU4UZmaW5URhZmZZThRmZpblRGFmZllOFGZmluVEYWZmWU4UZmaWNeGJQmJNh/UXSZw5UfG0MjgI0shjxgwYGhopnzdv9OtqWfV1Xbt1y4OD0Nf3/PJqvcZ2Bwef33ddHwCzZ9fHVi4PDRVtSUXdwcGRPsv2Gsc4e/boOSofs2ePxFVtv2yzjHvmzKJ+dQxln0NDRXk5JzPSEVqd92osM2aMzGHZ5owZIzHWjbca0+zZxbaN81fOS3Vd3X4qj5fqcTNjRvFcrV/GN3PmyDyVy+V2g4PF8rx5I3PTONdlrGWdav3qPJR1q+vLORwaGomtOgczZxaxz5s3up0y5vJRHWu538ptZs8u6pf7saxTnZMylvJRvsfKOKrHT3UOq8fK7Nmjx1Gds3nzRuJsjLtx/zUeF+X8VsvKmKqfBY3Pderen9XxVR/VcZX7oRxbOWfVz4oy1nLflO+/iaKImLjWKRJFBHM6qL8I6I/g6LH019/fH8PDw2PZtOy/VjlN0ujXzcrq2q2WlcvV/uq2beyjMca6Nuv6baf/Oo3btqpft+1469XF324sjfsmt3+bjbPZ/u4khk7mbSLb63YsE6kaa3X/jDf+dt+HzfprjKWT93wupm7sl/F8nEtaERH9dWXjPqOQ+JDEB9PrMyQuS6/3lzg3vf64xA0SyyW2TOveInGNxPUSPy7XN7Q9X+IiiWvT47XjjdfMzDrTjUtPVwL7pdf9wByJDdO6K4CNgeUR/Hla/ttU9ypg7wheCZwPHF/T9meBMyLYC/gr4Ct1AUg6UtKwpOHVq1d3YUhmZlaa2YU2VgB7SmwKPA1cR5Ew9gM+CPwJuLhS9y/S622ACyS2BjYC7q5p+43ArpVTsk0l5kSM/t4jIs4BzoHi0lMXxmRmZsm4E0UEz0jcDSwCrgZuBF4P7AjcCjwTQfnhvbbS5+eB0yP4nsQgMFTT/AyKs46nxhunmZmNTTfOKKC4/HQc8DfATcDpwIoIIvMFzVzg/vT6iCZ1LgGOAT4FILEwgpVdirnWwABcfvnIsgQnnzyyPHfu6NfHHjuyvHhxvt265YEBWLVq9N0WjfUa79QYGICVK0f3XdcHwKxZ9bGVy4sXw5Il8NhjRd299y7WDw7CsmXP33bxYjj1VHj66fq+Zs9+/pyU7UAR95o1sHbt6PmrjvNjH4Nttinm5IorinXVea+2fcop8LrXFXN4zz1Fvccfh402Gh1jdbwwEtPy5bDVViMxVOsvWQILF46sW7Dg+fupPF6qx035JWa1/oIFRXwbbDByp8pjjxXLa9eOtHXVVTAn3fpx7LHPn+sFC0bPx5o1I/UXLhyZh7Luo4+OrH/00ZGxLV06Els5B/fdB889B5tuWtw5VLZTxlzae++RsZb7bcmSYpvf/Q6efRZOOqnYj2vXFnWuuGJkTmAkFij218knF2PdaitYtKh+zst9NzBQxHzCCSPjWLlyZM6WLIGnniriXL58dNyNGo+LpUufX7ZgQRHTKaeMfBY0blensax8r1fH11i+fHkxf889B9ttV4xt1aqivHxd3vm0dGmxz2bOLI6R8r0+Ebpy15PEG4AfAvMieFLiDuCsCE6v3vUkcQhwUASLJA4GzgAeAS4D9opgsHrXk8QWwBeAXSiS2hURHJWLZbx3PZmZTUe5u54m/PbYyeZEYWbWuQm9PdbMzNZvThRmZpblRGFmZllOFGZmluVEYWZmWU4UZmaW5URhZmZZThRmZpblRGFmZllOFGZmluVEYWZmWU4UZmaW5URhZmZZThRmZpblRGFmZllOFGZmluVEYWZmWU4UZmaW5URhZmZZThRmZpblRGFmZllOFGZmluVEYWZmWU4UZmaW5URhZmZZThRmZpblRGFmZlk9TRQSa9LziyS+VVn/7xI3SvxDL+IaGmpvXa5Os/qDgx2Hk1XXXrO+c2MYHCzK+/pG6ubG02o+yu3Ldss4q/EODo4sl/1Wy6rP7fbXGF+zMQwOFn2Wj2oMdWMt1zXG2SyWctzV5Wrfdf00xll9rrZRjaex7VxMjf3VbVeOrzHGdua/UXUOmmkn9rr5qm5Xt49z7Vbbq4txaAhmzx5Znjev+TFcN6+NcZTbNx47Q0MjZXXttPM51HgctPM5NRaKiIlpuZ3OxZoI5jSs2wq4KoIdx9Jmf39/DA8PjzcuGqelbl1uu2b122mnE53EmutbGnkdMbLcbDytxlFtr7Hdapt166vtNz636q8x3mb7pDG+XF+5OFuNPTeXrfZT9blZe41tt4qp1T5sNu/tzH9dW61i6+R9lduX7c5tY51Ss/1dXS7XNTuGW/XRrJ9ceav3dquxdELSiojoryubEpeeJPokbk6LlwAvllgpsZ/EDhI/lFghcaXEzr2M1cxsupnZ6wBqvBW4OIKFABI/AY6K4E6JVwNfBPavbiDpSOBIgO22226SwzUzW79NxUTx3yTmAPsAF1ZOrWY11ouIc4BzoLj0NFnxmZlNB1M6UVBcGnu0PLswM7PJN6UTRQSPS9wtcWgEF0oIeEUEN0xkv4sXt7cuV6dZ/YGBscXUTF17zfrOjWFgoLhrYunS+rqtlpv1tWxZ0e6yZSP9VPssLVjw/Hiqz+3217jcbJ8MDMCqVaO3KWPIjbUxzmaxlOOuLlf7ruunWezVuWzcrrHtXEyN6o6dcnyNMXY6/2Ubre5qauf9UDdf1e3q9nGu3Wp71f1UbePUU0eW586FY4+tP4Zb7cOBAVi5sti+fG9V6yxZUpTl2sitq+6furF0y5S460mij+J7id2rr1OdlwBfArYGNgTOj+CUZm12464nM7PpJnfXU0/PKMpbYyNYBUViqL5Oy3cDb+pBeGZmxhS5PdbMzKYuJwozM8tyojAzsywnCjMzy3KiMDOzLCcKMzPLcqIwM7MsJwozM8tyojAzsywnCjMzy3KiMDOzLCcKMzPLcqIwM7MsJwozM8tyojAzsywnCjMzy3KiMDOzLCcKMzPLcqIwM7MsJwozM8tyojAzsywnCjMzy3KiMDOzLCcKMzPLcqIwM7MsJwozM8tyojAzs6wJSRQSQxLHjWG7QYl9KstLJQ7pbnTtGRpqXWdwsPM2Grdpp5/xarePsl5f39jaGMtYmm1Trq+Wt2p/aKh+u2Z1BwdHj7Vxm1axdRpfWacaZyfb1h1vnWzXztzU7ft2dPs47qS9XN12joPyubpfynno9Phr9pnQzrHUbh/N1vf1TdzniSKi+42KIWBNBJ8ez3YSS4GLI/hWu2309/fH8PBwJ902i4VWU9OqTl1547p2+hmvdvso67UT93j6aWebuljamW9oPoa6umX9uvZbxZZ73Um/nWw7nv2S27+dtNfN7brR3njGU52TUrO56uT4azeOTj8Pcu1U4x8LSSsior+urGtnFBInStwhcRWwU1q3g8QPJVZIXCmxc1r/FolrJK6X+LHElhJ9wFHAP0islNgvNf06iaslft2rswszs+msK4lCYk/gMGAhcCCwVyo6Bzgmgj2B44AvpvVXAXtH8ErgfOD4CFYBZwFnRLAwgitT3a2BfYGDgFPr+9eRkoYlDa9evbobQzIzs2Rml9rZD/hOBP8FIPE9YDawD3Bh5bRoVnreBrhAYmtgI+DuTNv/EcFzwC0SW9ZViIhzKJIS/f39E3whx8xseulWoqgzA3g0goU1ZZ8HTo/gexKDwFCmnacrr9W0lpmZTYhuJYorgKUSn0htvgU4G7hb4tAILpQQ8IoIbgDmAvenbY+otPMEsGmXYhqXxYtb1xkY6LyNxm3a6We82u2jrLdgwdjaGMtYmm1Trq+Wt2q/07rLlsGqVc23aRVbp32222YzdcdbJ9vVzWmjun3fjm4fx520l6vb7jHTWK+ch7EcU53E0e4x1047S5fCokX57ceqa3c9SZxI8aH/IPAb4DrgIuBLFN8zbAicH8EpEgcDZwCPAJcBe0UwKPEy4FvAc8AxwHup3PUksSaCObk4unXXk5nZdJK762lCbo/tJScKM7POTcrtsWZmtn5yojAzsywnCjMzy3KiMDOzLCcKMzPLcqIwM7MsJwozM8tyojAzsywnCjMzy3KiMDOzLCcKMzPLcqIwM7MsJwozM8tyojAzsywnCjMzy3KiMDOzLCcKMzPLcqIwM7MsJwozM8tyojAzsywnCjMzy3KiMDOzLCcKMzPLcqIwM7MsJwozM8tyojAzsywnCjMzy+p5opDok7i5YV2/xOfS60USZ6bXQxLH9SJOM7PpqueJok4EwxF8sJcxDA2Nr87gYHtttDJvXufbDA0V/beqk1vfjdjHoq7fiYilVZu58l7NTTu6GVunbbU65nptvO/puvLqci+Oi8nqUxExOT01C0D0ARdHsLvE9sBFwHnAQAQHSSwC+iM4WmIIWBPBp5u119/fH8PDw92Ii1ZTk6sjFc/jnd524hhL383aLdePpd9uqOt3ImJp1Warfdvjt01T3Yyt07am8rzA+N/TdeXV5V6Mv7v7Wysior+ubMqcUUjsRJEkFgHX9jYaMzMrTZVEMR/4LnB4BDd0urGkIyUNSxpevXp196MzM5vGpkqieAz4DbDvWDaOiHMioj8i+ufPn9/dyMzMprmZvQ4g+RPwl8CPJNYAD/Q4HjMzS6ZKoiCCJyUOAi4FPtrreBYvHl+dgYHu3AUyd27n2yxeDMuWta6TW9/O+CdCXb8TEUurNnPlvZqbdnQztk7bGhjoXt8TYbzv6bry6nIvjovJ6rPndz11W7fuejIzm07WibuezMxsanKiMDOzLCcKMzPLcqIwM7MsJwozM8tyojAzsywnCjMzy3KiMDOzLCcKMzPLcqIwM7MsJwozM8tyojAzsywnCjMzy3KiMDOzLCcKMzPLcqIwM7MsJwozM8tyojAzsywnCjMzy3KiMDOzLCcKMzPLcqIwM7MsJwozM8tyojAzsywnCjMzy3KiMDOzLCcKMzPLcqIwM7MsJwozM8tyojAzsywnCjMzy1JE9DqGrpK0GrhnjJtvATzUxXCmsuky1ukyTpg+Y/U4J8aCiJhfV7DeJYrxkDQcEf29jmMyTJexTpdxwvQZq8c5+XzpyczMspwozMwsy4litHN6HcAkmi5jnS7jhOkzVo9zkvk7CjMzy/IZhZmZZTlRmJlZlhNFIulNkm6XdJekE3odT7skrZJ0k6SVkobTus0lXSrpzvS8WVovSZ9LY7xR0h6Vdo5I9e+UdERl/Z6p/bvStprEsX1N0oOSbq6sm/CxNetjksc5JOn+tF9XSjqwUvbhFPPtkv5HZX3tMSzpJZKuSesvkLRRWj8rLd+VyvsmeJzbSvqppFsk/VLS36f169U+zYxz3d2nETHtH8AGwK+A7YGNgBuAXXsdV5uxrwK2aFj3SeCE9PoE4LT0+kDg/wEC9gauSes3B36dnjdLrzdLZb9IdZW2ffMkju11wB7AzZM5tmZ9TPI4h4Djaurumo7PWcBL0nG7Qe4YBr4JHJZenwW8P73+O+Cs9Pow4IIJHufWwB7p9SbAHWk869U+zYxznd2nk/KGn+oP4DXAjyrLHwY+3Ou42ox9Fc9PFLcDW6fXWwO3p9dnA+9orAe8Azi7sv7stG5r4LbK+lH1Jml8fYz+AJ3wsTXrY5LH2exDZdSxCfwoHb+1x3D6wHwImNl4rJfbptczUz1N4r79LvAX6+s+rRnnOrtPfemp8GLg3sryfWnduiCASyStkHRkWrdlRPw2vf4dsGV63WycufX31azvpckYW7M+JtvR6ZLL1yqXSjod5wuARyPi2Yb1o9pK5Y+l+hMuXRJ5JXAN6/E+bRgnrKP71Ili3bdvROwBvBn4gKTXVQuj+NNivbwHejLG1sP5+xKwA7AQ+C3wmR7EMCEkzQEuAo6NiMerZevTPq0Z5zq7T50oCvcD21aWt0nrpryIuD89Pwh8B3gV8HtJWwOk5wdT9WbjzK3fpmZ9L03G2Jr1MWki4vcRsTYingO+TLFfofNxPgzMkzSzYf2otlL53FR/wkjakOLD89yI+HZavd7t07pxrsv71ImicC3w0nQnwUYUXwJ9r8cxtSRpY0mblK+BA4CbKWIv7wQ5guIaKWn9u9PdJHsDj6XT8R8BB0jaLJ0OH0BxzfO3wOOS9k53j7y70lavTMbYmvUxacoPteQvKfYrFLEdlu5ueQnwUoovcGuP4fTX80+BQ9L2jXNWjvMQ4LJUf6LGJOCrwK0RcXqlaL3ap83GuU7v08n6QmeqPyjusLiD4i6DE3sdT5sxb09xJ8QNwC/LuCmuSf4EuBP4MbB5Wi/gC2mMNwH9lbb+BrgrPd5TWd+fDuhfAWcyuV92/jvFKfozFNdh3zsZY2vWxySP81/TOG6kePNvXal/Yor5dip3oTU7htNx8os0/guBWWn97LR8VyrffoLHuS/FJZ8bgZXpceD6tk8z41xn96l/wsPMzLJ86cnMzLKcKMzMLMuJwszMspwozMwsy4nCzMyynChsWpJ0hqRjK8s/kvSVyvJnJP3jGNselHRxk7J9Jf1C0m3pcWSlbH76xc/rJe0n6VBJt0r66Rhi+MhYYjer40Rh09XPgH0AJM0AtgB2q5TvA1zdTkOSNmiz3lbAecBREbEzxf3275P0P1OVNwA3RcQrI+JKin9P8bcR8fp22m/gRGFd40Rh09XVFL+6CUWCuBl4Iv1r31nALsB1kt6Q/sK/Kf2Q2yz47/8H5DRJ1wGHqvh/A25Ly/+7SZ8fAJZGxHUAEfEQcDxwgqSFFD+FfbCK/6tgMUUi+aqkT0naLZ2JrEw/KvfSFMc7K+vPlrSBpFOBP0vrzp2AubNpZmbrKmbrn4h4QNKzkrajOHv4OcUvb76G4hc3b6L4Q2op8IaIuEPSN4D3A0tSMw9HxB6SZlP8i9/9Kf5F7AVNut0N+HrDumFgt4hYKelkin99fDSApNdT/Cz1sKTPA5+NiHPTzzlsIGkX4O3AayPiGUlfBA6PiBMkHR0RC8c7T2bgMwqb3q6mSBJlovh5ZflnwE7A3RFxR6r/dYr/ZKhUJoSdU707o/ipg3+bgFh/DnxE0v8FFkTEHykuVe0JXCtpZVrefgL6tmnOicKms/J7ipdTXHpaTnFG0e73E0922N8tFB/sVXtS/E5XVkScB7wV+CPwA0n7U/wW0tcjYmF67BQRQx3GZNaSE4VNZ1cDBwF/iOLnn/8AzKNIFldT/EBbn6QdU/13AZfXtHNbqrdDWn5Hk/6+ACxK30cg6QXAaRTfTWRJ2h74dUR8juKXQl9B8SN3h0h6YaqzuaQFaZNnVPzUtdm4OVHYdHYTxd1OyxvWPRYRD0XEU8B7gAsl3QQ8R/H/E4+S6h0JfD99mV37fx1E8TPY7wS+LOk2imT0tYj4zzZifRtwc7rEtDvwjYi4BTiJ4n84vBG4lOK/+QQ4B7jRX2ZbN/jXY83MLMtnFGZmluVEYWZmWU4UZmaW5URhZmZZThRmZpblRGFmZllOFGZmlvX/AbG4/57xeoipAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH9bL4hR4T8W"
      },
      "source": [
        "Dictionary definitions\n",
        "\n",
        "Use wordnet synsets to get word definitions and examples of usage.\n",
        "The [0] is required because synsets returns a list, with an entry for each Part of Speech (POS)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_Kj6NwK3WB8",
        "outputId": "fdb6b4d9-7eee-46ef-c9e8-0d16297e9620"
      },
      "source": [
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import wordnet as wn\n",
        "w = wn.synsets(\"love\")[0]\n",
        "print(w.name(), '-', w.definition())\n",
        "print(w.examples())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "love.n.01 - a strong positive emotion of regard and affection\n",
            "['his love for his work', 'children need a lot of love']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_HayICn3WFI",
        "outputId": "c34bd931-af9b-4cd0-bc81-1282e0e6ade7"
      },
      "source": [
        "w = wn.synsets(\"love\")\n",
        "w"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('love.n.01'),\n",
              " Synset('love.n.02'),\n",
              " Synset('beloved.n.01'),\n",
              " Synset('love.n.04'),\n",
              " Synset('love.n.05'),\n",
              " Synset('sexual_love.n.02'),\n",
              " Synset('love.v.01'),\n",
              " Synset('love.v.02'),\n",
              " Synset('love.v.03'),\n",
              " Synset('sleep_together.v.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiWbwskV536w"
      },
      "source": [
        "Punctuation and Stop Words\n",
        "\n",
        "Text analysis is often faster and easier if you can remove useless words.\n",
        "NLTK provides a list of these stop words so it's easy to filter them out of your text prior to processing.\n",
        "\n",
        "Here, 15% of our text is punctuation, and 40% is stop words. So we shrink the text by more than half by stripping out punctuation and stop words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0cf9Qvb3WH7",
        "outputId": "16a5a9c9-0760-458b-843c-a7f386d272a0"
      },
      "source": [
        "from string import punctuation\n",
        "print(punctuation)\n",
        "without_punct = [w for w in text1 if w not in punctuation]  # this is called a list comprehension\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "sw = stopwords.words('english')\n",
        "print(sw)\n",
        "\n",
        "without_sw = [w for w in without_punct if w not in sw] \n",
        "\n",
        "print(len(text1))\n",
        "print(len(without_punct))\n",
        "print(len(without_sw))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
            "260819\n",
            "221767\n",
            "122226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsnWUGMB652O"
      },
      "source": [
        "Stemming and Lemmatization\n",
        "\n",
        "These term normalization algorithms strip the word endings off to reduce the number of root words for easier matching.\n",
        "\n",
        "This is useful for search term matching. \n",
        "https://www.nltk.org/api/nltk.stem.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGMR0c9Y3WKD",
        "outputId": "7716e8e5-07be-40ca-bec2-ed4fecd16a0a"
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "st = PorterStemmer()\n",
        "\n",
        "words = ['is', 'are', 'bought', 'buys', 'giving', 'jumps', 'jumped', 'birds', 'do', 'does', 'did', 'doing']\n",
        "for word in words:\n",
        "    print(word, st.stem(word))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is is\n",
            "are are\n",
            "bought bought\n",
            "buys buy\n",
            "giving give\n",
            "jumps jump\n",
            "jumped jump\n",
            "birds bird\n",
            "do do\n",
            "does doe\n",
            "did did\n",
            "doing do\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnI1oQ037tLn"
      },
      "source": [
        "WordNet Lemmatizer\n",
        "\n",
        "The difference is that the result of stemming may not be an actual word, but lemmatization returns the root word. NLTK supports both.\n",
        "\n",
        "You can also try the Lancaster or Snowball stemmers. The Snowball stemmer supports numerous languages: Arabic, Danish, Dutch, English, Finnish, French, German, Hungarian, Italian, Norwegian, Portuguese, Romanian, Russian, Spanish and Swedish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePyKJCpY7RLR",
        "outputId": "9717946f-f949-493e-afae-b394256b357a"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "wnl = WordNetLemmatizer()\n",
        "\n",
        "words = ['is', 'are', 'bought', 'buys', 'giving', 'jumps', 'jumped', 'birds', 'do', 'does', 'did', 'doing']\n",
        "\n",
        "for word in words:\n",
        "    print(word, wnl.lemmatize(word))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is is\n",
            "are are\n",
            "bought bought\n",
            "buys buy\n",
            "giving giving\n",
            "jumps jump\n",
            "jumped jumped\n",
            "birds bird\n",
            "do do\n",
            "does doe\n",
            "did did\n",
            "doing doing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbEYO6St790x"
      },
      "source": [
        "Sentence and Word Tokenizers\n",
        "\n",
        "Sentence tokenizer breaks text down into a list of sentences. It's pretty good at handling punctuation and decimal numbers.\n",
        "Word tokenizer breaks a string down into a list of words and punctuation.\n",
        "\n",
        "It is also easy to get parts of speech using nltk.pos_tag. There are different tagsets, depending on how much detail you want. I like universal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aU3wEdzv7RNg",
        "outputId": "6a549d9c-8d97-4b30-ba92-80ff1cb4538a"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "s = 'Hello. I am Joe! I like Python. 263.5 is a big number.'  # 4 sentences\n",
        "\n",
        "print(sent_tokenize(s))\n",
        "\n",
        "w = word_tokenize('The quick brown fox jumps over the lazy dog.')\n",
        "print(w)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello.', 'I am Joe!', 'I like Python.', '263.5 is a big number.']\n",
            "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49hb98FK8Ybj"
      },
      "source": [
        "Parts of Speech Tagging\n",
        "\n",
        "To break a block of text down into its parts of speech use pos_tag.\n",
        "The default tagset uses 2 or 3 letter tokens that are hard for me to understand. StackOverflow has a great decoder for the default POS tags.\n",
        "\n",
        "The Universal tagset gives a more familiar looking tag (noun, verb, adj).\n",
        "NLTK includes several other tagsets you can try."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyDBeG4i7RP8",
        "outputId": "4ad37ae1-a399-43ee-e9da-4f4cc78cd5f2"
      },
      "source": [
        "w = word_tokenize('The quick brown fox jumps over the lazy dog.')\n",
        "\n",
        "print(w)\n",
        "print(nltk.pos_tag(w))\n",
        "print(nltk.pos_tag(w, tagset='universal'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n",
            "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n",
            "[('The', 'DET'), ('quick', 'ADJ'), ('brown', 'NOUN'), ('fox', 'NOUN'), ('jumps', 'VERB'), ('over', 'ADP'), ('the', 'DET'), ('lazy', 'ADJ'), ('dog', 'NOUN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6NY7-Ru9Ro2"
      },
      "source": [
        "**Word2Vec**\n",
        "\n",
        "Word2Vec uses neural networks to analyze words in a corpus by using the contexts of words. It takes as its input a large corpus of text, and maps unique words to a vector space, such that words that share common contexts in the corpus are located in close proximity to one another in the space.\n",
        "\n",
        "Word2Vec does NOT look at word meanings, it only finds words that are used in combination with other words. So frying and pan may have a high similarity.\n",
        "\n",
        "You can see here the context of one word (pain) for two different corpora.\n",
        "\n",
        "This uses the popular gensim library, which is not part of NLTK."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfKNv90A7RSm",
        "outputId": "a8940957-6450-4e11-a2e6-3368e002a7bc"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "emma_vec = Word2Vec(gutenberg.sents('austen-emma.txt'))\n",
        "leaves_vec = Word2Vec(gutenberg.sents('whitman-leaves.txt'))\n",
        "\n",
        "print(emma_vec.wv.most_similar('love', topn=6))\n",
        "print(leaves_vec.wv.most_similar('pain', topn=6))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('natural', 0.9983057975769043), ('pleasant', 0.9981988668441772), ('strong', 0.9978015422821045), ('pleasing', 0.9977486729621887), ('ago', 0.997719407081604), ('exactly', 0.9974443912506104)]\n",
            "[('forever', 0.998204231262207), ('moment', 0.9981893301010132), ('ready', 0.9981735348701477), ('without', 0.9981714487075806), ('comes', 0.998169481754303), ('Now', 0.9981652498245239)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNk1zNRz7RWJ",
        "outputId": "4aa6c7ba-08af-444d-99b3-085ca46ed04a"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "import pprint as pp\n",
        "\n",
        "bible_sents = gutenberg.sents('bible-kjv.txt')\n",
        "sw = stopwords.words('english')\n",
        "\n",
        "bible = [[w.lower() for w in s if w not in punctuation and w not in sw] for s in bible_sents]\n",
        "print(len(bible))\n",
        "\n",
        "bible_vec = Word2Vec(bible)\n",
        "\n",
        "pp.pprint(bible_vec.wv.most_similar('god', topn=8))\n",
        "pp.pprint(bible_vec.wv.most_similar('creation', topn=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30103\n",
            "[('mercy', 0.9294182062149048),\n",
            " ('liveth', 0.9248984456062317),\n",
            " ('grace', 0.9246912002563477),\n",
            " ('christ', 0.9123010635375977),\n",
            " ('hosts', 0.8991404175758362),\n",
            " ('truth', 0.8991243243217468),\n",
            " ('salvation', 0.8953806161880493),\n",
            " ('spoken', 0.8948251008987427)]\n",
            "[('obedience', 0.980457067489624),\n",
            " ('scriptures', 0.9733983278274536),\n",
            " ('reigneth', 0.9712979793548584),\n",
            " ('impossible', 0.9712733626365662),\n",
            " ('sorry', 0.9709648489952087)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkJLjH5j-2DC"
      },
      "source": [
        "**k-Means Clustering**\n",
        "\n",
        "Clustering groups similar items together.\n",
        "The K-means clusterer starts with k arbitrarily chosen means (or centroids) then assigns each vector to the cluster with the closest mean. It then recalculates the means of each cluster as the centroid of its vector members. This process repeats until the cluster memberships stabilize. NLTK docs on this example.\n",
        "\n",
        "This example clusters int vectors, which you can think of as points on a plane. But you could also use clustering to cluster similar documents by vocabulary/topic."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N7lQaOG3WMh",
        "outputId": "c37f6725-a7c9-44f1-fbb0-e5629b1d74d4"
      },
      "source": [
        "import numpy as np\n",
        "from nltk.cluster import KMeansClusterer, euclidean_distance\n",
        "\n",
        "vectors = [np.array(f) for f in [[2, 1], [1, 3], [4, 7], [6, 7]]]\n",
        "means = [[4, 3], [5, 5]]\n",
        "\n",
        "km = KMeansClusterer(2, euclidean_distance, initial_means=means)\n",
        "clusters = km.cluster(vectors, True, trace=True)\n",
        "\n",
        "print('Clustered:', vectors)\n",
        "print('As:', clusters)\n",
        "print('Means:', km.means())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k-means trial 0\n",
            "iteration\n",
            "iteration\n",
            "Clustered: [array([2, 1]), array([1, 3]), array([4, 7]), array([6, 7])]\n",
            "As: [0, 0, 1, 1]\n",
            "Means: [array([1.5, 2. ]), array([5., 7.])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdM613A1AU3Q"
      },
      "source": [
        "**k-Means Clustering, \n",
        "we cluster an array of 6 points into 2 clusters.\n",
        "The initial centroids are randomly chosen by the clusterer, and it does 10 iterations to regroup the clusters and recalculate centroids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRcIP8kx-1OQ",
        "outputId": "a219616a-35eb-4d50-d0f9-c0eb0190e6ac"
      },
      "source": [
        "vectors = [np.array(f) for f in [[3, 3], [1, 2], [4, 2], [4, 0], [2, 3], [3, 1]]]\n",
        "\n",
        "# test k-means using 2 means, euclidean distance, and 10 trial clustering repetitions with random seeds\n",
        "clusterer = KMeansClusterer(2, euclidean_distance, repeats=10)\n",
        "clusters = clusterer.cluster(vectors, True)\n",
        "centroids = clusterer.means()\n",
        "print('Clustered:', vectors)\n",
        "print('As:', clusters)\n",
        "print('Means:', centroids)\n",
        "\n",
        "# classify a new vector\n",
        "vector = np.array([2,2])\n",
        "print('classify(%s):' % vector, end=' ')\n",
        "print(clusterer.classify(vector))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clustered: [array([3, 3]), array([1, 2]), array([4, 2]), array([4, 0]), array([2, 3]), array([3, 1])]\n",
            "As: [0, 0, 1, 1, 0, 1]\n",
            "Means: [array([2.        , 2.66666667]), array([3.66666667, 1.        ])]\n",
            "classify([2 2]): 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbuqHs9dAt96"
      },
      "source": [
        "\n",
        "\n",
        "Make a Scatter Plot of the two clusters using matplotlib.pyplot.\n",
        "We plot all the points in cluster-0 blue, and all the points in cluster-1 red. Then we plot the two centroids in orange."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "U6u6B2I9-1Q3",
        "outputId": "24096974-8834-405e-9886-c18c86976cd9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x0 = np.array([x[0] for idx, x in enumerate(vectors) if clusters[idx]==0])\n",
        "y0 = np.array([x[1] for idx, x in enumerate(vectors) if clusters[idx]==0])\n",
        "plt.scatter(x0,y0, color='blue')\n",
        "\n",
        "x1 = np.array([x[0] for idx, x in enumerate(vectors) if clusters[idx]==1])\n",
        "y1 = np.array([x[1] for idx, x in enumerate(vectors) if clusters[idx]==1])\n",
        "plt.scatter(x1,y1, color='red')\n",
        "\n",
        "xc = np.array([x[0] for x in centroids])\n",
        "yc = np.array([x[1] for x in centroids])\n",
        "plt.scatter(xc,yc, color='orange')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciFNQLub3WPM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBhFihPyBbsN"
      },
      "source": [
        "_____________"
      ]
    }
  ]
}