{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qjyy7b06dolv"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Jg-naszZdtN1"
      },
      "outputs": [],
      "source": [
        "# cd ../gdrive/My Drive/Colab Notebooks/_NLP/GPT-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohmeptNk4Mms"
      },
      "source": [
        "Reference - [Colab](https://colab.research.google.com/github/ilopezfr/gpt-2/blob/master/gpt-2-playground_.ipynb#scrollTo=tI-HVDbQS9dF) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv9X--HadtTO",
        "outputId": "7ae6fb97-1d4f-4c38-f872-8b12d278c5f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 4.5 kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 59.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 63.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 438 kB 76.6 MB/s \n",
            "\u001b[?25h  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "!pip install -q gpt-2-simple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "du_DZmjndtVy"
      },
      "outputs": [],
      "source": [
        "# importing simple gpt\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDi6BVztdtYU",
        "outputId": "a0e0e22f-01d5-441f-dd64-77ccad885001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# which GPU is running?\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_gjkfVLvz2z"
      },
      "source": [
        "## Downloading GPT-2\n",
        "If you're retraining a model on new text, you need to download the GPT-2 model first.\n",
        "\n",
        "There are three released sizes of GPT-2:\n",
        "\n",
        "1. 124M (default): the \"small\" model, 500MB on disk.\n",
        "2. 355M: the \"medium\" model, 1.5GB on disk.\n",
        "3. 774M: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n",
        "4. 1558M: the \"extra large\", true model. Will not work if a K80 GPU is attached to the notebook. (like 774M, it cannot be finetuned).\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing model_name in the cells below.\n",
        "\n",
        "The next cell downloads it from Google Cloud Storage and saves it in the Colaboratory VM at /models/<model_name>.\n",
        "\n",
        "This model isn't permanently saved in the Colaboratory VM; you'll have to redownload it if you want to retrain it at a later time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hd-dpDfGdtap",
        "outputId": "ee0dae5a-1a67-4042-8b53-6544dc2d14c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 512Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 4.85Mit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 427Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:10, 45.7Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 590Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 7.26Mit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 7.39Mit/s]\n"
          ]
        }
      ],
      "source": [
        "# let's download small model. \n",
        "gpt2.download_gpt2(model_name=\"124M\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dJo5yl1Ddtds"
      },
      "outputs": [],
      "source": [
        "file_name = \"mit_shakespeare.txt\"\n",
        "# /mit_shakespeare.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXaYKyCl1qlz",
        "outputId": "b0c97455-557d-4a6a-fe08-35984978f0ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "gpt2.mount_gdrive()\n",
        "# /content/mit_shakespeare.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "anS0k7tX3Izv",
        "outputId": "3e869a8b-845e-4e7f-b711-aac19e04ef41"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IkogDjgUdtie"
      },
      "outputs": [],
      "source": [
        "gpt2.copy_file_from_gdrive(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Nir86SBdtkt",
        "outputId": "58afbb73-4873-4734-ae38-37c7b4f5f0bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n",
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:07<00:00,  7.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 1850440 tokens\n",
            "Training...\n",
            "[10 | 155.42] loss=3.15 avg=3.15\n",
            "[20 | 288.25] loss=3.05 avg=3.10\n"
          ]
        }
      ],
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='124M',\n",
        "              steps=1000,\n",
        "              restore_from='fresh',\n",
        "              run_name='run1',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwACkXrKdtnc"
      },
      "outputs": [],
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZ5VZpz0dtqY"
      },
      "outputs": [],
      "source": [
        "gpt2.generate(sess, run_name='run1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6xSYXfhdtsv"
      },
      "outputs": [],
      "source": [
        "gpt2.generate(sess,\n",
        "              length=250,\n",
        "              temperature=0.7,\n",
        "              prefix=\"LORD\",\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZT9d30Edtvr"
      },
      "outputs": [],
      "source": [
        "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
        "\n",
        "gpt2.generate_to_file(sess,\n",
        "                      destination_path=gen_file,\n",
        "                      length=500,\n",
        "                      temperature=0.7,\n",
        "                      nsamples=100,\n",
        "                      batch_size=20\n",
        "                      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKsiTEh95HcG"
      },
      "outputs": [],
      "source": [
        "# may have to run twice to get file to download\n",
        "files.download(gen_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjBo8WHy5HfA"
      },
      "outputs": [],
      "source": [
        "gen_file"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Simple GPT-2 Application.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}